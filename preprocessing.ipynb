{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adcc2ae9",
   "metadata": {},
   "source": [
    "# Specify Paths "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ec8236",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7e6491c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fpga_v3_data_collection_path = \"/home/ndrakes1/force_estimation/preprocess/fpgav3-data-collection/\" # SET THIS ONCE\n",
    "preproces_path = \"/home/ndrakes1/force_estimation/preprocess/force-estimation-fpga-data-preprocess\" # SET THIS ONCE\n",
    "\n",
    "true_preprocess_path = \"~/force_estimation/preprocess/\"\n",
    "\n",
    "\n",
    "unit_convert_path = fpga_v3_data_collection_path + \"unit_convert/unit_convert.py\"\n",
    "pot_to_encoder_path = preproces_path + \"/pot_to_encoder.py\"\n",
    "si_unit_json_path = \"/home/ndrakes1/force_estimation/data/XML_FILES/sawRobotIO1394-PSM1-292409.xml.json\"\n",
    "unit_convert_cmd = \"python3 \" + unit_convert_path + \" -c \" + si_unit_json_path + \" -f \" \n",
    "\n",
    "train_name_path_csv = \"/home/ndrakes1/force_estimation/data/capture_2-17-26/10khz/freespace/train.csv\" # SET THIS\n",
    "val_test_name_path_csv = \"/home/ndrakes1/force_estimation/data/capture_2-17-26/10khz/freespace/val.csv\" # SET THIS\n",
    "\n",
    "train_name_path_pot_csv = train_name_path_csv.replace(\".csv\", \"_potEncoder.csv\")\n",
    "val_test_name_path_pot_csv = val_test_name_path_csv.replace(\".csv\", \"_potEncoder.csv\")\n",
    "\n",
    "train_name_path_unit_convert_csv = \"/home/ndrakes1/force_estimation/data/capture_2-17-26/10khz/freespace/train_unitConvert.csv\" # SET THIS\n",
    "val_ttest_name_path_unit_convert_csv = \"/home/ndrakes1/force_estimation/data/capture_2-17-26/10khz/freespace/val_unitConvert.csv\" # SET THIS\n",
    "train_name_path_unit_convert_pot_csv = train_name_path_pot_csv.replace(\".csv\", \"_unitConvert.csv\")\n",
    "val_ttest_name_path_unit_convert_pot_csv = val_test_name_path_pot_csv.replace(\".csv\", \"_unitConvert.csv\")\n",
    "\n",
    "path_to_data_foleder = \"/home/ndrakes1/force_estimation/data/capture_2-17-26/10khz/freespace/\"\n",
    "new_preprocessed_data_folder = \"/preprocessed\"\n",
    "\n",
    "ORIGINAL_FREQ = 10000\n",
    "\n",
    "CUTOFF = True\n",
    "CUTOFF_SECS = 20\n",
    "\n",
    "if CUTOFF == True:\n",
    "    new_preprocessed_data_folder += \"_CUTOFF_\" + str(CUTOFF_SECS)\n",
    "\n",
    "INTERPOLATE = True\n",
    "\n",
    "if INTERPOLATE == True:\n",
    "    new_preprocessed_data_folder += \"_INTERPOLATE\" \n",
    "\n",
    "\n",
    "FILTER = True\n",
    "FILTER_FREQ = 30\n",
    "FILTER_VELOCITY = True\n",
    "FILTER_POSITION = True\n",
    "\n",
    "if FILTER == True:\n",
    "    new_preprocessed_data_folder += \"_FILTER_\" + str(FILTER_FREQ)\n",
    "if FILTER_VELOCITY:\n",
    "    new_preprocessed_data_folder += \"_VEL_\" \n",
    "if FILTER_POSITION:\n",
    "    new_preprocessed_data_folder += \"_POS_\" \n",
    "\n",
    "DOWNSAMPLE = True\n",
    "DOWNSAMPLE_FREQ = 60\n",
    "DOWNSAMPLE_MOVING_AVERAGE = True\n",
    "\n",
    "if DOWNSAMPLE == True:\n",
    "    new_preprocessed_data_folder += \"_DOWNSAMPLE_\" + str(DOWNSAMPLE_FREQ)\n",
    "\n",
    "\n",
    "USE_POTS = True\n",
    "\n",
    "if USE_POTS:\n",
    "    unit_convert_train_input_csv = train_name_path_pot_csv\n",
    "    unit_convert_val_input_csv = val_test_name_path_pot_csv\n",
    "    train_preprocess_input_csv = train_name_path_unit_convert_pot_csv\n",
    "    val_preprocess_input_csv = val_ttest_name_path_unit_convert_pot_csv\n",
    "    new_preprocessed_data_folder += \"POT\"\n",
    "else:\n",
    "    unit_convert_train_input_csv = train_name_path_csv\n",
    "    unit_convert_val_input_csv = val_test_name_path_csv\n",
    "    train_preprocess_input_csv = train_name_path_unit_convert_csv\n",
    "    val_preprocess_input_csv = val_ttest_name_path_unit_convert_csv\n",
    "\n",
    "unit_convert_train_cmd = unit_convert_cmd + unit_convert_train_input_csv\n",
    "unit_convert_val_test_cmd = unit_convert_cmd + unit_convert_val_input_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "396a69fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='mkdir -p /home/ndrakes1/force_estimation/data/capture_2-17-26/10khz/freespace//preprocessed_CUTOFF_20_INTERPOLATE_FILTER_30_VEL__POS__DOWNSAMPLE_60POT/train/joints/ /home/ndrakes1/force_estimation/data/capture_2-17-26/10khz/freespace//preprocessed_CUTOFF_20_INTERPOLATE_FILTER_30_VEL__POS__DOWNSAMPLE_60POT/val/joints/ /home/ndrakes1/force_estimation/data/capture_2-17-26/10khz/freespace//preprocessed_CUTOFF_20_INTERPOLATE_FILTER_30_VEL__POS__DOWNSAMPLE_60POT/test/joints/', returncode=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## making preprocessed data dir \n",
    "import subprocess\n",
    "\n",
    "new_dir = path_to_data_foleder + new_preprocessed_data_folder\n",
    "train_sub = new_dir + \"/train/joints/\"\n",
    "val_sub = new_dir + \"/val/joints/\"\n",
    "test_sub = new_dir + \"/test/joints/\"\n",
    "mk_new_dir_cmd = \"mkdir -p \" + train_sub + \" \" + val_sub + \" \" + test_sub\n",
    "\n",
    "subprocess.run(mk_new_dir_cmd, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c3ba88",
   "metadata": {},
   "source": [
    "## paths for high freq preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac84764e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 /home/ndrakes1/force_estimation/preprocess/force-estimation-fpga-data-preprocess/preprocessing.py /home/ndrakes1/force_estimation/data/capture_2-17-26/10khz/freespace/train_potEncoder_unitConvert.csv /home/ndrakes1/force_estimation/data/capture_2-17-26/10khz/freespace//preprocessed_CUTOFF_20_INTERPOLATE_FILTER_30_VEL__POS__DOWNSAMPLE_60POT/train/joints/interpolated_all_joints.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "preprocessing_script_path = preproces_path + \"/preprocessing.py\"\n",
    "split_val_test_path = preproces_path + \"/split_val_test.py\"\n",
    "\n",
    "preprocessing_train_cmd = \"python3 \" + preprocessing_script_path + \" \" + train_preprocess_input_csv + \" \" + train_sub + \"interpolated_all_joints.csv\"\n",
    "preprocessing_val_test_cmd =\"python3 \" + preprocessing_script_path + \" \" + val_preprocess_input_csv + \" \" + val_sub + \"interpolated_all_joints.csv\"\n",
    "\n",
    "print(preprocessing_train_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08215924",
   "metadata": {},
   "source": [
    "# Unit Conversion to SI units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "994e35a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to /home/ndrakes1/force_estimation/data/capture_2-17-26/10khz/freespace/val_potEncoder_unitConvert.csv\n",
      "Data written to /home/ndrakes1/force_estimation/data/capture_2-17-26/10khz/freespace/train_potEncoder_unitConvert.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='python3 /home/ndrakes1/force_estimation/preprocess/fpgav3-data-collection/unit_convert/unit_convert.py -c /home/ndrakes1/force_estimation/data/XML_FILES/sawRobotIO1394-PSM1-292409.xml.json -f /home/ndrakes1/force_estimation/data/capture_2-17-26/10khz/freespace/train_potEncoder.csv', returncode=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "if USE_POTS:\n",
    "    pot_convert_train_cmd = \"python3 \" + pot_to_encoder_path + \" \" + train_name_path_csv + \" \" + train_name_path_pot_csv\n",
    "    pot_convert_val_test_cmd = \"python3 \" + pot_to_encoder_path + \" \" + val_test_name_path_csv + \" \" + val_test_name_path_pot_csv\n",
    "    subprocess.run(pot_convert_val_test_cmd, shell=True)\n",
    "    subprocess.run(pot_convert_train_cmd, shell=True)\n",
    "\n",
    "subprocess.run(unit_convert_val_test_cmd, shell=True)\n",
    "subprocess.run(unit_convert_train_cmd, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5af789",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f56adaee",
   "metadata": {},
   "source": [
    "# High Freq Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea2b2676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished preprocessing train \n",
      "preprocess split and val\n",
      "Validation set saved to val.csv 996800 rows\n",
      "Test set saved to test.csv 996800 rows\n",
      "split into val and test\n"
     ]
    }
   ],
   "source": [
    "# # interpolate train and place it in correct directory\n",
    "# # train\n",
    "subprocess.run(preprocessing_train_cmd, shell=True)\n",
    "print(\"finished preprocessing train \")\n",
    "\n",
    "## val test\n",
    "subprocess.run(preprocessing_val_test_cmd, shell=True)\n",
    "print(\"preprocess split and val\")\n",
    "\n",
    "# # split\n",
    "split_val_test_cmd = \"python3 \" + preproces_path + \"/split_val_test.py \" + \" \" + val_sub + \"interpolated_all_joints.csv\"\n",
    "subprocess.run(split_val_test_cmd, shell=True)\n",
    "print(\"split into val and test\")\n",
    "\n",
    "!mv {preproces_path}/val.csv {val_sub}interpolated_all_joints.csv\n",
    "!mv {preproces_path}/test.csv {test_sub}interpolated_all_joints.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb66830",
   "metadata": {},
   "source": [
    "## Preprocessed Training File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4b6589e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "train_file = os.path.join(train_sub, \"interpolated_all_joints.csv\")\n",
    "val_file = os.path.join(val_sub, \"interpolated_all_joints.csv\")\n",
    "test_file = os.path.join(test_sub, \"interpolated_all_joints.csv\")\n",
    "\n",
    "train_df = pd.read_csv(train_file, header=None)\n",
    "val_df =  pd.read_csv(val_file, header=None)\n",
    "test_df = pd.read_csv(test_file, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d9cd0e",
   "metadata": {},
   "source": [
    "## Cutoff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "341b5c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total rows:  5853072\n",
      "total rows:  996800\n",
      "total rows:  996800\n"
     ]
    }
   ],
   "source": [
    "from cutoff import truncate_dataframe\n",
    "\n",
    "\n",
    "if (CUTOFF == True):\n",
    "    ## TRAIN\n",
    "    FREQ =  ORIGINAL_FREQ if DOWNSAMPLE == False else DOWNSAMPLE_FREQ\n",
    "    ## TRAIN\n",
    "    train_df = truncate_dataframe(train_df, CUTOFF_SECS, FREQ)\n",
    "    val_df = truncate_dataframe(val_df, CUTOFF_SECS, FREQ)\n",
    "    test_df = truncate_dataframe(test_df, CUTOFF_SECS, FREQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a4e826",
   "metadata": {},
   "source": [
    "## FIR Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "147b1306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILTERED\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import filter  # regular import first\n",
    "importlib.reload(filter)\n",
    "\n",
    "\n",
    "\n",
    "if (FILTER == True):\n",
    "    # Design filter\n",
    "    fir_coeffs = filter.design_fir_filter(filter_type='kaiser', fs=ORIGINAL_FREQ, fC=FILTER_FREQ, order=30)\n",
    "\n",
    "    # Apply to train/val/test CSVs\n",
    "    train_df = filter.apply_filter_to_torque_feedback_df(train_df, fir_coeffs, filter_velocity=FILTER_VELOCITY, filter_position=FILTER_POSITION)\n",
    "    val_df = filter.apply_filter_to_torque_feedback_df(val_df, fir_coeffs, filter_velocity=FILTER_VELOCITY, filter_position=FILTER_POSITION)\n",
    "    test_df = filter.apply_filter_to_torque_feedback_df(test_df, fir_coeffs, filter_velocity=FILTER_VELOCITY, filter_position=FILTER_POSITION)\n",
    "\n",
    "    print(\"FILTERED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88050431",
   "metadata": {},
   "source": [
    "## Downsample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cd87252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from downsample import downsample_dataframe\n",
    "\n",
    "if (DOWNSAMPLE == True):\n",
    "    train_df = downsample_dataframe(train_df, ORIGINAL_FREQ, DOWNSAMPLE_FREQ, DOWNSAMPLE_MOVING_AVERAGE)\n",
    "    val_df = downsample_dataframe(val_df, ORIGINAL_FREQ, DOWNSAMPLE_FREQ, DOWNSAMPLE_MOVING_AVERAGE)\n",
    "    test_df = downsample_dataframe(test_df, ORIGINAL_FREQ, DOWNSAMPLE_FREQ, DOWNSAMPLE_MOVING_AVERAGE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89691a62",
   "metadata": {},
   "source": [
    "# Interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "629e9521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000e+00 1.47003817e-02 3.12999001e-02 ... 5.85031900e+02\n",
      " 5.85048500e+02 5.85058700e+02]\n",
      "[0.00000000e+00 1.46999880e-02 3.13000419e-02 ... 9.93988998e+01\n",
      " 9.94155000e+01 9.94256999e+01]\n",
      "[0.00000000e+00 1.46999897e-02 3.12999355e-02 ... 9.93989024e+01\n",
      " 9.94155000e+01 9.94256999e+01]\n"
     ]
    }
   ],
   "source": [
    "from interpolate_timestamps import interpolate_dataframe_to_sample_rate\n",
    "\n",
    "if (INTERPOLATE == True):\n",
    "\n",
    "    freq = 0\n",
    "\n",
    "    if (DOWNSAMPLE):\n",
    "        freq = DOWNSAMPLE_FREQ\n",
    "    else:   \n",
    "        freq = ORIGINAL_FREQ\n",
    "    \n",
    "    train_df = interpolate_dataframe_to_sample_rate(train_df, freq)\n",
    "    val_df = interpolate_dataframe_to_sample_rate(val_df, freq)\n",
    "    test_df = interpolate_dataframe_to_sample_rate(test_df, freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5775ab5e",
   "metadata": {},
   "source": [
    "## SAVE TO CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcb06e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(train_file, index=False, header=False)\n",
    "val_df.to_csv(val_file, index=False, header=False)\n",
    "test_df.to_csv(test_file, index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
